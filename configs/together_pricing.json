{
  "provider": "together",
  "models": {
    "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8": {
      "input_per_million": 0.27,
      "output_per_million": 0.85
    },
    "meta-llama/Llama-4-Scout-17B-16E-Instruct": {
      "input_per_million": 0.18,
      "output_per_million": 0.59
    },
    "meta-llama/Llama-3.3-70B-Instruct-Turbo": {
      "input_per_million": 0.88,
      "output_per_million": 0.88
    },
    "meta-llama/Llama-3.2-3B-Instruct-Turbo": {
      "input_per_million": 0.06,
      "output_per_million": 0.06
    },
    "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo": {
      "input_per_million": 3.5,
      "output_per_million": 3.5
    },
    "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo": {
      "input_per_million": 0.88,
      "output_per_million": 0.88
    },
    "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo": {
      "input_per_million": 0.18,
      "output_per_million": 0.18
    },
    "deepseek-ai/DeepSeek-R1": {
      "input_per_million": 3.0,
      "output_per_million": 7.0
    },
    "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B": {
      "input_per_million": 0.18,
      "output_per_million": 0.18
    },
    "deepseek-ai/DeepSeek-R1-Distill-Llama-70B": {
      "input_per_million": 2.0,
      "output_per_million": 2.0
    },
    "deepseek-ai/DeepSeek-V3": {
      "input_per_million": 1.25,
      "output_per_million": 1.25
    },
    "deepseek-ai/DeepSeek-V3-0324": {
      "input_per_million": 0.6,
      "output_per_million": 1.7
    },
    "Qwen/Qwen3-235B-A22B-Instruct-2507-FP8": {
      "input_per_million": 0.2,
      "output_per_million": 0.6
    },
    "Qwen/Qwen2.5-72B-Instruct-Turbo": {
      "input_per_million": 1.2,
      "output_per_million": 1.2
    },
    "Qwen/Qwen2.5-Coder-32B-Instruct": {
      "input_per_million": 0.8,
      "output_per_million": 0.8
    },
    "Qwen/QwQ-32B-Preview": {
      "input_per_million": 1.2,
      "output_per_million": 1.2
    },
    "mistralai/Mistral-7B-Instruct-v0.2": {
      "input_per_million": 0.2,
      "output_per_million": 0.2
    },
    "mistralai/Mistral-Small-24B-Instruct-2501": {
      "input_per_million": 0.8,
      "output_per_million": 0.8
    },
    "mistralai/Mixtral-8x7B-Instruct-v0.1": {
      "input_per_million": 0.6,
      "output_per_million": 0.6
    },
    "google/gemma-3n-E4B-it": {
      "input_per_million": 0.02,
      "output_per_million": 0.04
    }
  },
  "metadata": {
    "updated": "2026-01-04",
    "source": "doppler:ai_providers"
  }
}
