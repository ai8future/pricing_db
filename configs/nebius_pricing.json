{
  "provider": "nebius",
  "billing_type": "token",
  "models": {
    "meta-llama/Llama-3.3-70B-Instruct": {
      "input_per_million": 0.13,
      "output_per_million": 0.4,
      "batch_multiplier": 0.50,
      "batch_cache_rule": "stack"
    },
    "meta-llama/Llama-3.1-405B-Instruct": {
      "input_per_million": 1.0,
      "output_per_million": 3.0,
      "batch_multiplier": 0.50,
      "batch_cache_rule": "stack"
    },
    "meta-llama/Llama-3.1-8B-Instruct": {
      "input_per_million": 0.02,
      "output_per_million": 0.06,
      "batch_multiplier": 0.50,
      "batch_cache_rule": "stack"
    },
    "deepseek-ai/DeepSeek-R1-0528": {
      "input_per_million": 0.8,
      "output_per_million": 2.4,
      "batch_multiplier": 0.50,
      "batch_cache_rule": "stack"
    },
    "deepseek-ai/DeepSeek-V3": {
      "input_per_million": 0.5,
      "output_per_million": 1.5,
      "batch_multiplier": 0.50,
      "batch_cache_rule": "stack"
    },
    "Qwen/Qwen3-235B-A22B-Instruct": {
      "input_per_million": 0.2,
      "output_per_million": 0.6,
      "batch_multiplier": 0.50,
      "batch_cache_rule": "stack"
    },
    "Qwen/Qwen3-235B-A22B-Thinking": {
      "input_per_million": 0.2,
      "output_per_million": 0.8,
      "batch_multiplier": 0.50,
      "batch_cache_rule": "stack"
    },
    "Qwen/Qwen2.5-72B-Instruct": {
      "input_per_million": 0.13,
      "output_per_million": 0.4,
      "batch_multiplier": 0.50,
      "batch_cache_rule": "stack"
    },
    "Qwen/QwQ-32B": {
      "input_per_million": 0.15,
      "output_per_million": 0.45,
      "batch_multiplier": 0.50,
      "batch_cache_rule": "stack"
    },
    "Qwen/Qwen3-Coder-480B": {
      "input_per_million": 0.4,
      "output_per_million": 1.8,
      "batch_multiplier": 0.50,
      "batch_cache_rule": "stack"
    },
    "NousResearch/Hermes-3-Llama-3.1-70B": {
      "input_per_million": 0.13,
      "output_per_million": 0.4,
      "batch_multiplier": 0.50,
      "batch_cache_rule": "stack"
    },
    "NousResearch/Hermes-3-Llama-3.1-405B": {
      "input_per_million": 1.0,
      "output_per_million": 3.0,
      "batch_multiplier": 0.50,
      "batch_cache_rule": "stack"
    },
    "moonshot-ai/Kimi-K2-Instruct": {
      "input_per_million": 0.5,
      "output_per_million": 2.4,
      "batch_multiplier": 0.50,
      "batch_cache_rule": "stack"
    },
    "THUDM/GLM-4.5": {
      "input_per_million": 0.6,
      "output_per_million": 2.2,
      "batch_multiplier": 0.50,
      "batch_cache_rule": "stack"
    },
    "THUDM/GLM-4.5-Air": {
      "input_per_million": 0.2,
      "output_per_million": 1.2,
      "batch_multiplier": 0.50,
      "batch_cache_rule": "stack"
    },
    "gpt-oss-120b": {
      "input_per_million": 0.15,
      "output_per_million": 0.6,
      "batch_multiplier": 0.50,
      "batch_cache_rule": "stack"
    },
    "gpt-oss-20b": {
      "input_per_million": 0.05,
      "output_per_million": 0.2,
      "batch_multiplier": 0.50,
      "batch_cache_rule": "stack"
    }
  },
  "image_models": {
    "flux-schnell": { "price_per_image": 0.0013 },
    "flux-dev": { "price_per_image": 0.025 },
    "sdxl": { "price_per_image": 0.008 }
  },
  "metadata": {
    "updated": "2026-01-24",
    "source_urls": ["https://nebius.com/prices-ai-studio", "https://nebius.com/services/token-factory/batch-inference"],
    "notes": [
      "Batch API: 50% discount with up to 5M requests per file",
      "Supports up to 500 files per user simultaneously",
      "OpenAI SDK compatible"
    ]
  }
}
